{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from google.cloud import storage\n",
    "from oauth2client.client import GoogleCredentials\n",
    "import os\n",
    "import google.auth\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import pymysql\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from re import sub\n",
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import preprocess_string, split_alphanum, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric, remove_stopwords, strip_short, stem_text\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import de_core_news_sm\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "pd.options.display.max_columns = 99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy    \n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words_nltk = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_german_list = []\n",
    "with open('./../stopwords-de/stopwords-de.json') as f:\n",
    "    git_german_list.append(json.load(f))\n",
    "    git_german_list = [i for i in git_german_list[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(git_german_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_stop_word_list_spacy = [i for i in nlp.Defaults.stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the stopword lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two stop word list to make it more comprehensive\n",
    "\n",
    "def combining_stopwords(list_A, list_B):\n",
    "    for i in list_B:\n",
    "        if i not in list_A:\n",
    "            list_A.append(i)\n",
    "    return list_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_stop_words = combining_stopwords(git_german_list, german_stop_words_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "geman_stop_words = combining_stopwords(german_stop_words, nlp_stop_word_list_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "633"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(german_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('./../test_data.json') as f:\n",
    "    lines = [line for line in f.readlines() if line.strip()]\n",
    "    lines = [json.loads(line) for line in lines]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [i['full_text'] for i in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r\"http\\S+\", \"\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@lovesgym_m @St_Dittes @bodoramelow @berny13189 @cdu_thueringen @Nightmare_Keks @BildungTH Das Bildungsministerium Thüringen hat jetzt eine Pressemitteilung zum Thema rausgegeben https://t.co/we2sSbRZuv'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_alphanumeric_or_space = re.compile('[^(\\w|\\s|\\d)]')\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), remove_URL,strip_tags, strip_punctuation, strip_multiple_whitespaces,\n",
    "                       strip_numeric, strip_short]  \n",
    "self_nlp = spacy.load('de_core_news_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1 = []\n",
    "output_2 = []\n",
    "docs = []\n",
    "docs_lem_ = []\n",
    "results = []\n",
    "output_final = []\n",
    "for text in test_data:\n",
    "    words = preprocess_string(text, filters=CUSTOM_FILTERS)\n",
    "    output_1.append(words)\n",
    "    words_2 = [i for i in words if i not in german_stop_words]\n",
    "    output_2.append(words_2)\n",
    "    doc = ' '.join(words).lower()\n",
    "    docs.append(doc)\n",
    "    doc_lem = nlp(doc)\n",
    "    docs_lem_.append(doc_lem)\n",
    "    results_ = ' '.join([x.lemma_ for x in doc_lem])\n",
    "    results.append(results_)\n",
    "    output_final.append(sub(not_alphanumeric_or_space, '', results_))\n",
    "    #doc = ' '.join(words).lower()\n",
    "    #doc_lem = nlp(doc)\n",
    "    #result = ' '.join([x.lemma_ for x in doc_lem])\n",
    "    #output.append((not_alphanumeric_or_space, '', result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abbiwire robbi hartmutschilk markusblume afd derspiegel vortanzen der sein doch der mein mein namen artikulieren gelle lass mal nicht der noch fehler machen ich glauben ich haben genug argumente obwohl bei sich austauschen',\n",
       " 'ich glauben nicht der der cdu oder csu der bundestagswahl gewinnen sonntag september mein diepartei dieparteirlp menschenleben retten und nicht wegschauen seawatchcrew niemehrcducsu politikversagen lebenretten',\n",
       " 'buecherwurm herrpandabaer diepartei ich kennen leute der der schon einen paar mal machen haben alle sein gut als gar nicht wählen',\n",
       " 'bayernpartei efaparty okay und sein dann der problem wenn ich sage dass ich von jemand nicht regieren werden mögen wenns ich nur bayern gehen sollen nicht ganz regieren kommen mein damit nicht klaren wie man sonst auf bayern hass kommen sollen bei sich weiß ich nämlich nicht',\n",
       " 'relang goeringeckardt regen und coronatote einen merkwürdig vergleich',\n",
       " 'dietmarbartsch ulfposh  stalinistisch  dies kontext',\n",
       " 'dietmarbartsch markus soeder arminlaschet dielinke spdde der gruenen der arm der gruenen einer grr bündnis wenn markus soeder aufstellen werden wählen ich grün werden arminlaschet eher fdp auch wenn weh tun aber einen räterepublik brauchen niemand',\n",
       " 'dietmarbartsch markus soeder arminlaschet dielinke spdde der gruenen gut für deutschland sein wenn mein kommunisten nie mehr regierungverantwortung kommen   ',\n",
       " 'dietmarbartsch friedrichmerz ich habe gut tun',\n",
       " 'rosels fms munich ronzheimer roettgen nzz nhaerting wollen angeblich mein gesundheit schützen aber setzen der recht au ',\n",
       " 'kuehnikev lucianocali spdbt',\n",
       " 'sigmargabriel precedentbad der geplant einheitlich regeln können jedoch dazu fahren dass einen ganze generation von schülerinnen und schülern kein beständigen schulunterricht mehr bekommen denn der virus werden sich noch lang begleiten und leben nach inzidenzen bedeuten schulschliessungen bundesweit',\n",
       " 'ronzheimer bild arminlaschet thorsten frei jtrittin wissing heute zum erst mal dies format sehen erfrischen progressiv und prime time ready danke ronzheimer',\n",
       " 'schaefer bild jtrittin der tatsächlich nutzen sollen man belegen ausgangspflicht sein gut der leute dann draußen sein und dort wenig infektionen stattfinden     man können auch infektionsvermeidungstreffpunkte schaffen menschen menschen treffen müssen alternativlosesdenkenschadet',\n",
       " 'schaefer jtrittin bild man muss übrigens der freiheitseinschränkung begründen',\n",
       " 'schaefer bild jtrittin der tatsächlich nutzen sollen man belegen ausgangspflicht sein gut der leute dann draußen sein und dort wenig infektionen stattfinden     man können auch infektionsvermeidungstreffpunkte schaffen menschen menschen treffen müssen alternativlosesdenkenschadet',\n",
       " 'schaefer jtrittin bild nein herr trittin der hase laufen andersrum',\n",
       " 'hoellenaufsicht marvinschuth katjakipping beid',\n",
       " 'grüße gehen raus mpstephanweil und gtonne',\n",
       " 'saltytrees drosten niedersachsens mpstephanweil heute morgenmagazin ich sehen nirgends einen exponentiell wachstum der ',\n",
       " 'epsilon tobiashans wohl eher der ice beginnen auf höhe der erst bahnsteigkante bremsen bahnhof anhalten',\n",
       " 'madmax kienastdirk bodoramelow jaja soll der denn mein',\n",
       " 'lovesgym dittes bodoramelow berny cdu thueringen nightmare keks bildungth der bildungsministerium thüringen haben jetzt einen pressemitteilung zum thema rausgegeben',\n",
       " 'fan tas tisch herrpandabaer joerg meuthen alice weidel messen mit zweierlei messen sein schon immer der kernkompetenz dies leute',\n",
       " 'bernhardzimniok ich schließen sich der worten von tino chrupalla und bedanken sich nicht nur bei der helfern der der afdbpt orga ']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
